{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f5c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üõ†Ô∏è Fast Environment Setup\n",
    "# @markdown This cell uses pre-compiled binaries to save time. (~45 seconds)\n",
    "\n",
    "# 1. Fix the 'jedi' dependency error and install server tools\n",
    "!pip install jedi huggingface_hub pyngrok nest_asyncio fastapi uvicorn -q\n",
    "\n",
    "# 2. Install pre-compiled llama-cpp-python with CUDA support\n",
    "# This skips the 5-minute \"building wheel\" process\n",
    "!pip install llama-cpp-python[server] --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n",
    "\n",
    "import nest_asyncio\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3a227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching meta-llama-3.1-8b.Q8_0.gguf from tspec2/redstring-8gb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a4931522fe43de85c4685247c56366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta-llama-3.1-8b.Q8_0.gguf:   0%|          | 0.00/8.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cached at: /root/.cache/huggingface/hub/models--tspec2--redstring-8gb/snapshots/15408353b64155f2a0b79ca513812aa9b38eb7e0/meta-llama-3.1-8b.Q8_0.gguf\n"
     ]
    }
   ],
   "source": [
    "REPO_ID = \"tspec2/redstring-8gb\"\n",
    "FILENAME = \"meta-llama-3.1-8b.Q8_0.gguf\" \n",
    "\n",
    "print(f\"Fetching {FILENAME} from {REPO_ID}...\")\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=FILENAME\n",
    ")\n",
    "\n",
    "print(f\"Model cached at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9179db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n",
      "\n",
      "‚ú® API IS LIVE! ‚ú®\n",
      "Copy this into your local app: https://inerasably-unpromotive-branda.ngrok-free.dev/v1\n"
     ]
    }
   ],
   "source": [
    "# @title Start the API Server\n",
    "NGROK_TOKEN = \"39pFdrEYO2brshKa669babIg7Nr_5pY9xXUPgS7rumDHdeu5Y\"\n",
    "\n",
    "!ngrok config add-authtoken {NGROK_TOKEN}\n",
    "ngrok.kill()\n",
    "public_url = ngrok.connect(8000).public_url\n",
    "\n",
    "def start_api():\n",
    "    cmd = f\"python3 -m llama_cpp.server --model {model_path} --n_gpu_layers -1 --n_ctx 8192 --host 0.0.0.0 --port 8000\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "threading.Thread(target=start_api, daemon=True).start()\n",
    "print(f\"\\n‚ú® API IS LIVE! ‚ú®\")\n",
    "print(f\"Copy this into your local app: {public_url}/v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
